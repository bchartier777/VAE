## Overview
This is an unofficial implementation of a vanilla VAE.  

VAEs apply the Variational Inference framework to autoencoders.  VAEs are stochastic generative models which implement an encoder, a decoder and a probabilistic distribution over the latent space.  Since they are generative models, the latent space can be sampled during and after training and synthetic examplars generated by the decoder.

The primary purpose of this implementation is to evaluate:
 - Multiple Encoder and Decoder networks
 - Two loss functions, one using the KL Divergence and the second using the Binary cross-entropy
    - Both loss functions use the reconstruction loss.
    - Source changes are required to enable BCE: The methods are calc_loss_KLD and calc_loss_BCE
 - Train using no image transform and two different grayscale transforms
 - Average episodic return for a limited number of seeds and hyperparameters

The following are not implemented:
 - Eval model
 - Checkpoint model archive and retrieval

## Input dataset
The version of MNIST downloaded with the TorchVision Dataset object.

## Performance
This has been tested for performance, including total, reconstruction and KL Divergence losses,
on MNIST only.

## Python version and Conda environment
This has been tested with Python 3.7.4 on Win 10.  Use of a virtual environment is recommended.
Following is a Conda implementation:

```
conda create --name vae_env python==3.7.4 pip
conda activate
pip install -r requirements.txt
```

The requirements.txt file was generated with pipreqs, not the environment
configuration from the reference repo, but should be correct.

## Usage
All execution parameters are implemented in parse_args in utils.py.  Following is a sample train
execution:

```
python main.py --user_epochs 3  --lr 1e-3 --batch_size 100  --weight_decay 1e-5 --data_folder ./data --seed 3435 1>ExecOut\stdOutVAE.txt  2>ExecOut\stdErrVAE.txt
```

Other train execution examples are in Exec1.bat.

## Output
In addition to outputting the KL Divergence, reconstruction and total losses to stdOut, 
validation image grids are output to a user-defined folder every epoch.

## Results
Using the default parameters, and 'class Encoder_v1', the model generates losses similar in range to the original repo 
listed in the References section below.

## References
The original VAE paper: Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014
https://arxiv.org/abs/1312.6114

The primary reference repo was Shayne Obrien, generative-model folder, [here](https://github.com/shayneobrien/generative-models),
which contains multiple well-written GANs and two VAEs.

